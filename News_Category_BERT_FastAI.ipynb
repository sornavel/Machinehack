{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "News Category_BERT_FastAI",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "fZEBwIuqdq4_",
        "colab_type": "code",
        "outputId": "b469b783-6f98-44af-8d73-7bbff8bd725b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 618
        }
      },
      "source": [
        "!pip install PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "import pandas as pd\n",
        "\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "download = drive.CreateFile({'id': '1jPZAGYcuyJdvpuFXzX6yfiTV4qZKk_v1'})\n",
        "download.GetContentFile('Data_Train.xlsx')\n",
        "train_df = pd.read_excel('Data_Train.xlsx')\n",
        "\n",
        "train_df.head()\n",
        "\n",
        "download = drive.CreateFile({'id': '1fYtpRafrbg75Qgbn8eW_uiVIhieMqm21'})\n",
        "download.GetContentFile('Data_Test.xlsx')\n",
        "test_df = pd.read_excel('Data_Test.xlsx')\n",
        "\n",
        "test_df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting PyDrive\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/52/e0/0e64788e5dd58ce2d6934549676243dc69d982f198524be9b99e9c2a4fd5/PyDrive-1.3.1.tar.gz (987kB)\n",
            "\r\u001b[K     |▎                               | 10kB 16.7MB/s eta 0:00:01\r\u001b[K     |▋                               | 20kB 1.7MB/s eta 0:00:01\r\u001b[K     |█                               | 30kB 2.5MB/s eta 0:00:01\r\u001b[K     |█▎                              | 40kB 1.7MB/s eta 0:00:01\r\u001b[K     |█▋                              | 51kB 2.1MB/s eta 0:00:01\r\u001b[K     |██                              | 61kB 2.5MB/s eta 0:00:01\r\u001b[K     |██▎                             | 71kB 2.9MB/s eta 0:00:01\r\u001b[K     |██▋                             | 81kB 3.3MB/s eta 0:00:01\r\u001b[K     |███                             | 92kB 3.7MB/s eta 0:00:01\r\u001b[K     |███▎                            | 102kB 2.8MB/s eta 0:00:01\r\u001b[K     |███▋                            | 112kB 2.8MB/s eta 0:00:01\r\u001b[K     |████                            | 122kB 2.8MB/s eta 0:00:01\r\u001b[K     |████▎                           | 133kB 2.8MB/s eta 0:00:01\r\u001b[K     |████▋                           | 143kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████                           | 153kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 163kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 174kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████                          | 184kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 194kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 204kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████                         | 215kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 225kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 235kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████                        | 245kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 256kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 266kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████                       | 276kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 286kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 296kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████                      | 307kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 317kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 327kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████                     | 337kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 348kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 358kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████                    | 368kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 378kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 389kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 399kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 409kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 419kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 430kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 440kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 450kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 460kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 471kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 481kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████                | 491kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 501kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 512kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 522kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 532kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 542kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 552kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 563kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 573kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 583kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 593kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 604kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 614kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 624kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 634kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 645kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 655kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 665kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 675kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 686kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 696kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 706kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 716kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 727kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 737kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 747kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 757kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 768kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 778kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 788kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 798kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 808kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 819kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 829kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 839kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 849kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 860kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 870kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 880kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 890kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 901kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 911kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 921kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 931kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 942kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 952kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 962kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 972kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 983kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 993kB 2.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: google-api-python-client>=1.2 in /usr/local/lib/python3.6/dist-packages (from PyDrive) (1.7.10)\n",
            "Requirement already satisfied: oauth2client>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from PyDrive) (4.1.3)\n",
            "Requirement already satisfied: PyYAML>=3.0 in /usr/local/lib/python3.6/dist-packages (from PyDrive) (3.13)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->PyDrive) (0.0.3)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->PyDrive) (3.0.0)\n",
            "Requirement already satisfied: six<2dev,>=1.6.1 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->PyDrive) (1.12.0)\n",
            "Requirement already satisfied: google-auth>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->PyDrive) (1.4.2)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.9.2 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->PyDrive) (0.11.3)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->PyDrive) (4.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->PyDrive) (0.4.6)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->PyDrive) (0.2.6)\n",
            "Requirement already satisfied: cachetools>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.4.1->google-api-python-client>=1.2->PyDrive) (3.1.1)\n",
            "Building wheels for collected packages: PyDrive\n",
            "  Building wheel for PyDrive (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for PyDrive: filename=PyDrive-1.3.1-cp36-none-any.whl size=27435 sha256=2d14eee5a9aebe232a61fa09442b8dc411005fbc42e4fbc0b5d44bd908099139\n",
            "  Stored in directory: /root/.cache/pip/wheels/fa/d2/9a/d3b6b506c2da98289e5d417215ce34b696db856643bad779f4\n",
            "Successfully built PyDrive\n",
            "Installing collected packages: PyDrive\n",
            "Successfully installed PyDrive-1.3.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>STORY</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2019 will see gadgets like gaming smartphones ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>It has also unleashed a wave of changes in the...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>It can be confusing to pick the right smartpho...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>The mobile application is integrated with a da...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>We have rounded up some of the gadgets that sh...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               STORY\n",
              "0  2019 will see gadgets like gaming smartphones ...\n",
              "1  It has also unleashed a wave of changes in the...\n",
              "2  It can be confusing to pick the right smartpho...\n",
              "3  The mobile application is integrated with a da...\n",
              "4  We have rounded up some of the gadgets that sh..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-c5JP8QsfCYI",
        "colab_type": "code",
        "outputId": "041448f6-c5a2-4f6f-87f6-d9070f8e63b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "!pip install pytorch-pretrained-bert==0.4.0\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import os\n",
        "from fastai.text import * \n",
        "from fastai.callbacks import *\n",
        "from pytorch_pretrained_bert.modeling import BertConfig, BertForSequenceClassification\n",
        "from pytorch_pretrained_bert import BertTokenizer\n",
        "from shutil import copyfile\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "# nltk for preprocessing of text data\n",
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "\n",
        "# sklearn for preprocessing and machine learning models\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.ensemble import AdaBoostClassifier,VotingClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from xgboost import XGBClassifier \n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pytorch-pretrained-bert==0.4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/95/68/84de54aea460eb5b2e90bf47a429aacc1ce97ff052ec40874ea38ae2331d/pytorch_pretrained_bert-0.4.0-py3-none-any.whl (45kB)\n",
            "\r\u001b[K     |███████▎                        | 10kB 18.9MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 20kB 1.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 30kB 2.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 40kB 1.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 51kB 2.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert==0.4.0) (1.9.205)\n",
            "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert==0.4.0) (1.1.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert==0.4.0) (2.21.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert==0.4.0) (1.16.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert==0.4.0) (4.28.1)\n",
            "Requirement already satisfied: botocore<1.13.0,>=1.12.205 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert==0.4.0) (1.12.205)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert==0.4.0) (0.9.4)\n",
            "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert==0.4.0) (0.2.1)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert==0.4.0) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert==0.4.0) (2019.6.16)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert==0.4.0) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert==0.4.0) (1.24.3)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.205->boto3->pytorch-pretrained-bert==0.4.0) (2.5.3)\n",
            "Requirement already satisfied: docutils<0.15,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.205->boto3->pytorch-pretrained-bert==0.4.0) (0.14)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\"->botocore<1.13.0,>=1.12.205->boto3->pytorch-pretrained-bert==0.4.0) (1.12.0)\n",
            "Installing collected packages: pytorch-pretrained-bert\n",
            "Successfully installed pytorch-pretrained-bert-0.4.0\n",
            "Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sRNB-BO3fOJL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = train_df\n",
        "df['word_count'] = df['STORY'].str.split().map(len)\n",
        "q = df[(df['word_count']>=200)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3gdNrYsQu94_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_df['word_count'] = test_df['STORY'].str.split().map(len)\n",
        "p = test_df[(test_df['word_count']>=200)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X5Ie9oOuvMPw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_df.drop(['word_count'],axis=1,inplace=True)\n",
        "df.drop(['word_count'],axis=1,inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XuBc1ACpfTyB",
        "colab_type": "code",
        "outputId": "cb5f2ab2-7d6b-41bf-ed4f-b9a4aaa4f7f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import gc\n",
        "gc.collect()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "29"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I2CaF40YgeWc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['Politics'] = df['SECTION'].apply(lambda x: 1. if x==0 else 0.)\n",
        "df['Technology'] = df['SECTION'].apply(lambda x: 1. if x==1 else 0.)\n",
        "df['Entertainment'] = df['SECTION'].apply(lambda x: 1. if x==2 else 0.)\n",
        "df['Business'] = df['SECTION'].apply(lambda x: 1. if x==3 else 0.)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cgVVSJQcVbwA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = df[:int(len(df)*.8)]\n",
        "valid = df[int(len(df)*.8):]\n",
        "\n",
        "train.to_csv('train.csv',index_label=False )\n",
        "valid.to_csv('valid.csv',index_label=False )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YH-xMqfsWUq4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Config(dict):\n",
        "    def __init__(self, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        for k, v in kwargs.items():\n",
        "            setattr(self, k, v)\n",
        "    \n",
        "    def set(self, key, val):\n",
        "        self[key] = val\n",
        "        setattr(self, key, val)\n",
        "\n",
        "config = Config(\n",
        "    testing=False,\n",
        "    bert_model_name=\"bert-large-uncased\",\n",
        "    max_lr=3e-5,\n",
        "    epochs=4,\n",
        "    use_fp16=True,\n",
        "    bs=8,\n",
        "    discriminative=False,\n",
        "    max_seq_len=256,\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O2vNlbbQgaJ5",
        "colab_type": "code",
        "outputId": "e5bd9ccd-da5b-40ea-88db-ff431be4c2fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "bert_tok = BertTokenizer.from_pretrained(config.bert_model_name)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 231508/231508 [00:00<00:00, 5603054.40B/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g1RplteBgz2Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class FastAiBertTokenizer(BaseTokenizer): \n",
        "    \"\"\"Wrapper around BertTokenizer to be compatible with fast.ai\"\"\"\n",
        "    def __init__(self, tokenizer: BertTokenizer, max_seq_len: int=128, **kwargs): \n",
        "         self._pretrained_tokenizer = tokenizer \n",
        "         self.max_seq_len = max_seq_len \n",
        "    def __call__(self, *args, **kwargs): \n",
        "         return self \n",
        "    def tokenizer(self, t:str) -> List[str]: #Limits the maximum sequence length\n",
        "        return [\"[CLS]\"] + self._pretrained_tokenizer.tokenize(t)[:self.max_seq_len - 2] + [\"[SEP]\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VOyHjg1Cg-LJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fastai_tokenizer = Tokenizer(tok_func=FastAiBertTokenizer(bert_tok, max_seq_len=config.max_seq_len), pre_rules=[], post_rules=[])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jl5pgdn2hDWL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def _join_texts(texts:Collection[str], mark_fields:bool=False, sos_token:Optional[str]=BOS):\n",
        "    \"\"\"Borrowed from fast.ai source\"\"\"\n",
        "    if not isinstance(texts, np.ndarray): texts = np.array(texts)\n",
        "    if is1d(texts): texts = texts[:,None]\n",
        "    df = pd.DataFrame({i:texts[:,i] for i in range(texts.shape[1])})\n",
        "    text_col = f'{FLD} {1} ' + df[0].astype(str) if mark_fields else df[0].astype(str)\n",
        "    if sos_token is not None: text_col = f\"{sos_token} \" + text_col\n",
        "    for i in range(1,len(df.columns)):\n",
        "        #text_col += (f' {FLD} {i+1} ' if mark_fields else ' ') + df[i]\n",
        "        text_col += (f' {FLD} {i+1} ' if mark_fields else ' ') + df[i].astype(str)\n",
        "    return text_col.values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LV2NVsCmhLUV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path = Path(os.path.abspath(os.curdir))\n",
        "train, val = [pd.read_csv(path / fname) for fname in [\"train.csv\", \"valid.csv\"]]\n",
        "\n",
        "test = test_df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c9tju9VRhSVJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if config.testing:\n",
        "    train = train.head(64)\n",
        "    val = val.head(64)\n",
        "    test = test.head(64)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BwBav8HVhgoL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fastai_bert_vocab = Vocab(list(bert_tok.vocab.keys()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aYAQQm4ngPNl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fastai_tokenizer = Tokenizer(tok_func=FastAiBertTokenizer(bert_tok, max_seq_len=config.max_seq_len), \n",
        "                             pre_rules=[], post_rules=[])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4BZSu-26hQUT",
        "colab_type": "code",
        "outputId": "6cce05bf-a8c2-499f-9674-bd2c0a3d58f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        }
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>STORY</th>\n",
              "      <th>SECTION</th>\n",
              "      <th>Politics</th>\n",
              "      <th>Technology</th>\n",
              "      <th>Entertainment</th>\n",
              "      <th>Business</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>But the most painful was the huge reversal in ...</td>\n",
              "      <td>3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>How formidable is the opposition alliance amon...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Most Asian currencies were trading lower today...</td>\n",
              "      <td>3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>If you want to answer any question, click on ‘...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>In global markets, gold prices edged up today ...</td>\n",
              "      <td>3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               STORY  ...  Business\n",
              "0  But the most painful was the huge reversal in ...  ...       1.0\n",
              "1  How formidable is the opposition alliance amon...  ...       0.0\n",
              "2  Most Asian currencies were trading lower today...  ...       1.0\n",
              "3  If you want to answer any question, click on ‘...  ...       0.0\n",
              "4  In global markets, gold prices edged up today ...  ...       1.0\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WMLoYLA8gTS8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "label_cols = [\"Politics\", \"Technology\", \"Entertainment\", 'Business']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U7PotQRQhaIf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "databunch = TextDataBunch.from_df(\".\", train, val, test,\n",
        "                   tokenizer=fastai_tokenizer,\n",
        "                   vocab=fastai_bert_vocab,\n",
        "                   include_bos=False,\n",
        "                   include_eos=False,\n",
        "                   text_cols=\"STORY\",\n",
        "                   label_cols=label_cols,\n",
        "                   bs=config.bs,\n",
        "                   collate_fn=partial(pad_collate, pad_first=False, pad_idx=0),\n",
        "              )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0RQMk4PWiTeW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BertTokenizeProcessor(TokenizeProcessor):\n",
        "    def __init__(self, tokenizer):\n",
        "        super().__init__(tokenizer=tokenizer, include_bos=False, include_eos=False)\n",
        "\n",
        "class BertNumericalizeProcessor(NumericalizeProcessor):\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super().__init__(*args, vocab=Vocab(list(bert_tok.vocab.keys())), **kwargs)\n",
        "\n",
        "def get_bert_processor(tokenizer:Tokenizer=None, vocab:Vocab=None):\n",
        "    \"\"\"\n",
        "    Constructing preprocessors for BERT\n",
        "    We remove sos/eos tokens since we add that ourselves in the tokenizer.\n",
        "    We also use a custom vocabulary to match the numericalization with the original BERT model.\n",
        "    \"\"\"\n",
        "    return [BertTokenizeProcessor(tokenizer=tokenizer),\n",
        "            NumericalizeProcessor(vocab=vocab)]\n",
        "\n",
        "class BertDataBunch(TextDataBunch):\n",
        "    @classmethod\n",
        "    def from_df(cls, path:PathOrStr, train_df:DataFrame, valid_df:DataFrame, test_df:Optional[DataFrame]=None,\n",
        "                tokenizer:Tokenizer=None, vocab:Vocab=None, classes:Collection[str]=None, text_cols:IntsOrStrs=1,\n",
        "                label_cols:IntsOrStrs=0, label_delim:str=None, **kwargs) -> DataBunch:\n",
        "        \"Create a `TextDataBunch` from DataFrames.\"\n",
        "        p_kwargs, kwargs = split_kwargs_by_func(kwargs, get_bert_processor)\n",
        "        # use our custom processors while taking tokenizer and vocab as kwargs\n",
        "        processor = get_bert_processor(tokenizer=tokenizer, vocab=vocab, **p_kwargs)\n",
        "        if classes is None and is_listy(label_cols) and len(label_cols) > 1: classes = label_cols\n",
        "        src = ItemLists(path, TextList.from_df(train_df, path, cols=text_cols, processor=processor),\n",
        "                        TextList.from_df(valid_df, path, cols=text_cols, processor=processor))\n",
        "        src = src.label_for_lm() if cls==TextLMDataBunch else src.label_from_df(cols=label_cols, classes=classes)\n",
        "        if test_df is not None: src.add_test(TextList.from_df(test_df, path, cols=text_cols))\n",
        "        return src.databunch(**kwargs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZSqzOL2aiVfu",
        "colab_type": "code",
        "outputId": "1f941fdd-758d-45d9-cf50-c26c0271f6a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "bert_model = BertForSequenceClassification.from_pretrained(config.bert_model_name, num_labels=4)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1248501532/1248501532 [00:24<00:00, 51154187.81B/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sJ8Gr-ACie5g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss_func = nn.BCEWithLogitsLoss()\n",
        "from fastai.callbacks import CSVLogger"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RTdXDX0KiiNg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learner = Learner(databunch, bert_model,loss_func=loss_func, callback_fns=[partial(CSVLogger, append=True)])\n",
        "if config.use_fp16: learner = learner.to_fp16()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jds03XsHinjr",
        "colab_type": "code",
        "outputId": "d8a25a64-2826-4a7a-bf70-0575029581a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        }
      },
      "source": [
        "learner.fit_one_cycle(4, 3e-5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.071360</td>\n",
              "      <td>0.056850</td>\n",
              "      <td>06:15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.054638</td>\n",
              "      <td>0.035068</td>\n",
              "      <td>06:20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.012324</td>\n",
              "      <td>0.022944</td>\n",
              "      <td>06:21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.010694</td>\n",
              "      <td>0.024125</td>\n",
              "      <td>06:18</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l3TT7YDnirGe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_preds_as_nparray(ds_type) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    the get_preds method does not yield the elements in order by default\n",
        "    we borrow the code from the RNNLearner to resort the elements into their correct order\n",
        "    \"\"\"\n",
        "    preds = learner.get_preds(ds_type)[0].detach().cpu().numpy()\n",
        "    #y = learner.get_preds(ds_type)[1].detach().cpu().numpy()\n",
        "    \n",
        "    sampler = [i for i in databunch.dl(ds_type).sampler]\n",
        "    reverse_sampler = np.argsort(sampler)\n",
        "    \n",
        "    return preds[reverse_sampler, :]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OpRFXlwEiuxm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "preds = get_preds_as_nparray(DatasetType.Test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d-EuPiwsixIE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "idx = np.argmax(preds, axis=-1)\n",
        "y_preds = np.zeros(preds.shape)\n",
        "y_preds[np.arange(preds.shape[0]), idx] = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ovCD5DFKrsS9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_preds\n",
        "preds= y_preds"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TtQx26KOjKu5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = pd.DataFrame({0:preds[:,0],1:preds[:,1],2:preds[:,2], 3:preds[:,3]})\n",
        "s = pd.get_dummies(dataset).idxmax(1)\n",
        "dataseti = pd.DataFrame({'SECTION':s})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SkAQR82CFL4E",
        "colab_type": "code",
        "outputId": "15c23078-5905-44e8-fc6d-36dbb4f9ef00",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        }
      },
      "source": [
        "dataseti.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SECTION</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   SECTION\n",
              "0        1\n",
              "1        2\n",
              "2        1\n",
              "3        1\n",
              "4        1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Serm_qEHFYLP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataseti.to_excel('submission.xlsx')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YYwHhMuCkqvB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "files.download('submission.xlsx')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}